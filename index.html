<!DOCTYPE HTML>
<html>
	<head>
		<title>Henry Han</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<meta property="og:url" content="https://henryshan.com" />
		<meta property="og:title" content="Henry Han" />
		<meta property="og:type" content="website" />
		<meta property="og:description" content="Computer Science and Statistics student at Swarthmore College." />
		<meta name="description" content="Computer Science and Cognitive Science major at Swarthmore College." />
		<meta property="og:image" content="images/penn_landing.jpg" />
	</head>
	<body>

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo -->
						<div id="logo">
							<span class="image avatar48"><img src="images/avi.jpg" alt="" /></span>
							<h1 id="title">Henry S Han</h1>
							<p>Swarthmore College '20</p>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<!--

								Prologue's nav expects links in one of two formats:

								1. Hash link (scrolls to a different section within the page)

								   <li><a href="#foobar" id="foobar-link" class="icon fa-whatever-icon-you-want skel-layers-ignoreHref"><span class="label">Foobar</span></a></li>

								2. Standard link (sends the user to another page/site)

								   <li><a href="http://foobar.tld" id="foobar-link" class="icon fa-whatever-icon-you-want"><span class="label">Foobar</span></a></li>

							-->
							<ul>
								<li><a href="#top" id="top-link" class="skel-layers-ignoreHref"><span class="icon fa-home">Intro</span></a></li>
								<li><a href="#portfolio" id="portfolio-link" class="skel-layers-ignoreHref"><span class="icon fa-th">Portfolio</span></a></li>
								<li><a href="#fakebananas" id="fakebananas-link" class="skel-layers-ignoreHref"><span>Fake Bananas</span></a></li>
                                <li><a href="#lotus" id="lotus-link" class="skel-layers-ignoreHref"><span>Lotus Journal</span></a></li>
                                <li><a href="#crumb" id="crumb-link" class="skel-layers-ignoreHref"><span>Crumb Cafe</span></a></li>
                                <li><a href="#nbascraper" id="nbascraper-link" class="skel-layers-ignoreHref"><span>NBA Statistics Scraper</span></a></li>
								<li><a href="#nbashotchart" id="nbashotchart-link" class="skel-layers-ignoreHref"><span>NBA Shot Chart</span></a></li>
								<li><a href="#featureimportance" id="featureimportance-link" class="skel-layers-ignoreHref"><span>Feature Importance Analysis</span></a></li>
								<li><a href="#superpixels" id="superpixels-link" class="skel-layers-ignoreHref"><span>Superpixels!</span></a></li>
								<li><a href="#potassium" id="potassium-link" class="skel-layers-ignoreHref"><span>Importance of Potassium</span></a></li>
								<li><a href="#paces" id="paces-link" class="skel-layers-ignoreHref"><span>Paces Cafe</span></a></li>
								<li><a href="#latenite" id="latenite-link" class="skel-layers-ignoreHref"><span>Late Nite</span></a></li>
								<li><a href="#reikiOM" id="reikiom-link" class="skel-layers-ignoreHref"><span>Reiki OM</span></a></li>
								<li><a href="#photography" id="photography-link" class="skel-layers-ignoreHref"><span>Photography</span></a></li>
								<li><a href="#djai" id="djai-link" class="skel-layers-ignoreHref"><span>DJai</span></a></li>
								<li><a href="#about" id="about-link" class="skel-layers-ignoreHref"><span class="icon fa-user">About Me</span></a></li>
								<!-- <li><a href="#contact" id="contact-link" class="skel-layers-ignoreHref"><span class="icon fa-envelope">Contact</span></a></li> -->
								<li><iframe src="https://open.spotify.com/follow/1/?uri=spotify:artist:6dDv1g33LC4F6YxGnthZrf&size=detail&theme=dark"
									width="300" height="56" scrolling="no" frameborder="0" style="border:none; overflow:hidden;" allowtransparency="true"></iframe></li>
							</ul>
						</nav>

				</div>

				<div class="bottom">

					<!-- Social Icons -->
						<ul class="icons">
							<li><a target="_blank" href="https://twitter.com/hankster_han" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a target="_blank" href="https://facebook.com/hanksterhan" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
							<li><a target="_blank" href="https://instagram.com/hanksterhan/" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a target="_blank" href="https://github.com/hanksterhan" class="icon fa-github"><span class="label">Github</span></a></li>
							<li><a target="_blank" href="https://linkedin.com/in/henryshan/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
						</ul>

				</div>

			</div>

		<!-- Main -->
			<div id="main">

				<!-- Intro -->
					<section id="top" class="one dark cover">
						<div class="container">
							<header>

							</header>

							<footer>
								<br />
								<br />
								<br />
								<br />
								<br />
							</footer>

						</div>
					</section>

					<div class="container">
						<br />
						<center>
							<h2 class="major"><strong>Hi! I'm Henry</strong></h2>
							<p><strong>Swarthmore College &nbsp;&bull;&nbsp; Sushi Chef &nbsp;&bull;&nbsp;
								 PNW &nbsp;&bull;&nbsp; Musician &nbsp;&bull;&nbsp; Data Scientist</strong></p>
						</center>
					</div>

				<!-- Portfolio -->
					<section id="portfolio" class="two">
						<div class="container">

							<header>
								<h2>Portfolio</h2>
							</header>

							<div class="row">
								<div class="12u 12u$(mobile)">
									<article class="item" id="fakebananas">
										<header>
											<a target="_blank" href="https://github.com/likeaj6/FakeBananas"><h2 class='major'><strong>Fake Bananas</strong></h2></a>
											<img src="images/banana.png" alt="bananas"/>
											<p>
												<a target="_blank" href="https://github.com/likeaj6/FakeBananas"><strong>Fake Bananas</strong></a> is a fake news detector web app based on stance detection, natural language processing and machine learning.
												At HackMIT 2017, Fake Bananas finished in the top 10 teams out of over 400 teams and 1250 hackers. Fake Bananas also
												won Best AI/Hack for Social Good from Baidu and the prize for the Most Interesting Use of Data from Hudson River Trading. <br /><br />
												Our fake news detection is based on the concept of <strong><i>stance detection.</i></strong> Fake news is tough to identify. Many 'facts' are
												highly complex and difficult to check, or exist on a 'continuum of truth' or are compound sentences with act and fiction overlapping. The best way to
												attack this problem is not through fact checking, but by comparing how reputable sources feel about a claim.
											</p>
											<img class="image fit" src="images/fakebananas.png"  />
											<p>
												How FakeBananas works:
											</p>
											<p>
												<ol>
													<li>
														1. Users input a claim like <i>"The Afghanistan war was bad for the world"</i>
													</li>
													<li>
														2. Our program will search the thousands of global and local news sources for their 'stance' on that topic.
													</li>
													<li>
														3. We run sources through our Reputability Algorithm. If lots of reputable sources all agree with your claim, then it's probably true.
													</li>
													<li>
														4. Then we cite our sources so our users can click through and read more about that topic!
													</li>
												</ol>
												I was primarily in charge of web scraping for articles. Given a user URL or claim, I used Microsoft's Azure Cognitive and IBM's Natural Language Processing
												to parse the article or claim and perform keyword extraction. I then used combinations of the keywords to collect up to a few thousand articles
												from Event Registry's database to pass on to the machine learning model. Here I aired on the side of collecting more rather than fewer articles
												because the machine learning will accurately determine relevancy further in the pipeline. <br />
											</p>
											<p>
												Moving forward, we hope to launch a public facing web application and potentially even a browser plug-in that can detect
												news articles and display what our pipeline returns.
											</p>
											<a target="_blank" href="https://github.com/likeaj6/FakeBananas"><strong> -- Link to Github -- </strong></a>
										</header>
									</article>

                                    <article class="item" id="lotus">
										<header>
											<a target="_blank" href="https://github.com/KastanDay/BananaExpress"><h2 class='major'><strong>Lotus Journal</strong></h2></a>
											<p>
												<a target="_blank" href="https://github.com/KastanDay/BananaExpress"><strong>Lotus Journal</strong></a> is a self-writing journal
												At HackMIT 2018, Lotus Journal finished in the top 10 teams out of over 400 teams and 1250 hackers. Lotus Journal also won the Azure Champ prize from Microsoft and Most Interesting Use of Text-Based Machine Learning from Quora.
											</p>
                                            <img class="image fit" src="images/lotus_journal.png" alt="bananas"/>

											<p>
												How Lotus Journal works:
											</p>
											<p>
												<ol>
													<li>
														1. User pictures are uploaded into a journal entry</i>
													</li>
													<li>
														2. We use image2text libraries and metadata from the pictures to generate a caption of what is going on in the picture, and if provided, location and date.
													</li>
													<li>
														3. We use this information to generate headings and prompts. In the screenshot above, the user only provided the picture of a man climbing. Our algorithm was able to extract the activity, rock climbing, the location, Rumney, and time of day, morning. Based on this information, we were able to generate a heading and prompt.
													</li>
													<li>
														4. As users type, the text is fed to my algorithm in real time. My algorithm does keyword extraction and matches them against the corpus of previous journal entries. My algorithm looks for similar temporal, locational, and linguistic keywords.
													</li>
                                                    <li>
                                                        5. This keyword information is then passed through my rule-based system to generate grammatically correct open-ended questions geared towards reflection. <br /> Example of generated question: "How was climbing today compared to 2 weeks ago in Wenatche, WA?"
                                                    </li>
												</ol>
												I was primarily in charge of the real time question generation based on user input. My algorithm does keyword extraction and matches them against the corpus of previous journal entries. My algorithm looks for similar temporal, locational, and linguistic keywords. This keyword information is then passed through my rule-based system to generate grammatically correct open-ended questions geared towards reflection. Question generation was particularly  difficult because if the keyword was an activity, for example, I would need to take into account the tense of the verb used. Climb, climbed, will climb, climbing, etc. all need to be handled independently and tense gathered from context. 
											</p>
											<p>
												Moving forward, we hope to turn this into a startup. We want to incorporate numerous data streams as users are able to provide them, data streams like fitbit data, sleep data, fitness and nutrition data, moods, progress tracking from apps like duolingo, etc. Over time, there will be plenty of user data on which machine learning can be conducted to find relationships and correlations. As we gain expertise in wellbeing, suggestions can be made to provide users insights into their lives.
											</p>
											<a target="_blank" href="https://github.com/KastanDay/BananaExpress"><strong> -- Link to Github -- </strong></a>
										</header>
									</article>


									<article class="item" id="nbascraper">
										<header>
											<a target="_blank" href='https://github.com/hanksterhan/NBA-Statistics-Scraper'><h2 class="major"><strong>NBA Statistics Scraper</strong></h2></a>
											<p>I built a <a target="_blank" href='https://github.com/hanksterhan/NBA-Statistics-Scraper'>web scraper</a> that gathered statistical information from every active player in the NBA in the
												2016-2017 season, as well as offensive and defensive team stats for each team.
												The data was pulled, cleaned, and displayed using a combination of the python libraries Numpy, Pandas, Bokeh, and BeautifulSoup.
												Hover over the graph to see some statistic.	The legend in the bottom right is also interactive, click on a position to try it out!</p>
											<object data=fantasy_ppg_ppm4.html width=100% height='450'>
												<embed src=fantasy_ppg_ppm4.html width=100% height=100% />
											</object>
											<p>
												Moving forward, I would like to analyze the data that I compiled and create a machine learning model that can predict roughly how well a player is going to do
												based on recent performances, offensive/defensive team metrics, and other statistics.
											</p>
											<a target="_blank" href='https://github.com/hanksterhan/NBA-Statistics-Scraper'><strong> -- Link to Github -- </strong></a>
										</header>
									</article>

									<article class="item" id="nbashotchart">
										<header>
											<a target="_blank" href='https://github.com/hanksterhan/NBAShotChartApp'><h2 class="major"><strong>NBA Shot Chart ShinyR App</strong></h2></a>
											<p>
												For my data science class, my partner, Alex Mandel, and I created this <a target="_blank" href="https://github.com/hanksterhan/NBAShotChartApp">project</a> to explore how NBA players shot charts.
												We were interested in seeing how well the top 25 NBA players perform. We look at different areas of the court and can see where they made the shot from and in different quarters or for an entire season.
												We downloaded and cropped our court images from Sports Illustrated . We downloaded our player data from NBA Savant and downloaded the NBA schedule from Kaggle .
												Finally, we scraped the NBA abbreviations from Wikipedia which helped us match a lot of our data. The app is hosted <a target="_blank" href = "http://shiny.swarthmore.edu:3838/hhan3/NBAShotChartApp/">here.</a>
											</p>

											<iframe id= 'nbashotchart' src="http://shiny.swarthmore.edu:3838/hhan3/NBAShotChartApp/" style="border: none; width: 100%; height: 600px;"></iframe>

											<p>
												Moving forward, I would like to analyze the data that we compiled and create a machine learning model that can predict what a player's shot chart will be on a particular night.
												I have read about existing projects that have been particular successful with these kind of predictions with deep neural nets.
											</p>
											<a target="_blank" href='https://github.com/hanksterhan/NBAShotChartApp'><strong> -- Link to Github -- </strong></a> <br />
											<a target="_blank" href = "http://shiny.swarthmore.edu:3838/hhan3/NBAShotChartApp/"><strong> -- Link to App -- </strong></a>
										</header>
									</article>

									<article class="item" id="featureimportance">
										<header>
											<h2 class="major"><strong>Analysis of Feature Selection Across Different Machine Learning Algorithms</strong></h2>
											<p>
												For my machine learning class, my partner and I chose to do an analysis on how different machine learning algorithms handle feature selection and dimensionality reduction
												implicitly or explictly. We chose 4 machine learning models: support vector machines, Bayesian networks, and logistic regression with L1 and L2 norms. We compared the results to
												existing preprocessing techniques that are used for dimensionality reduction - Principle Component Analysis and Linear Discriminant Analysis. The linear transformation using PCA
												is shown below.
											</p>
											<img src="images/education_PCA.png" class="image"/>
											<p>
												Abstract
											</p>
											<p>
												Feature importance and dimensionality reduction are important for effectively visualizing and interpreting real-world datasets,
												as well as improving prediction accuracy. Using the <a target="_blank" href="https://www.kaggle.com/aljarah/xAPI-Edu-Data">Students Academic Performance Dataset from Kaggle</a>,
												we implemented support vector machines, Bayesian networks, and logistic regression with L1 and L2 norms. These algorithms with various hyperparamets were implemented
												to determine feature importance and predictive power of the models. These results were then compared to the important features determined from the preprocessing techniques:
												Principle Component Anaylsis (PCA) and Linear Discriminant Analysis (LDA). Using R<sup>2</sup> values, which explain the percentage of the response variable explained by the
												variation in the model, it was found that L1 regularized logistic regression and Bayesian networks best fit the data. The higher R<sup>2</sup> values identify that these algorithms
												had the most predictive power, allowing them to identify the ost important features in the dataset. SVM, LDA and L2 regularized logistic regression least accurately fit the data with
												SVM having the next highest R<sup>2</sup> value and L1 having the lowerst. The important features between Bayesian networks, PCA, and LDA were compared, while the irrelevant features
												determined by SVM and L1/L2 logistic regression were also evaluated.
											</p>
											<p>
												Moving forward, I would like to do more analysis in the sci-kit learn library feature_selection. I would also like to use multiple datasets and have more baselines to compare results to.
											</p>
											<a target="_blank" href="hhan3-aclark2.pdf">-- Link to paper --</a>
										</header>
									</article>

									<article class="item" id="potassium">
										<header>
											<h2 class="major"><strong>Why You Need 12 Bananas Worth of Potassium Every Day</strong></h2>
											<p>
												Potassium is the third most abundant mineral in the body so it is no surprise that a potassium deficient diet can lead to a slew of problems.
												The most common symptoms of potassium deficiency include fatigue, muscle weakness, and brain fog. In addition, supplementing potassium has
												been proven to stimulate neural activities like memorization and learning, help lower blood pressure, and reduce stress and anxiety.
												Potassium plays a vital role in maintaining water balance in the body, and a sufficient concentration is also required for regular contraction
												and relaxation of muscles.To an extent, a state of potassium deficiency can be thought of as being intoxicated by alcohol - where both are
												characterized with poor muscle coordination, lapses in judgement, and potentially even poor memory. The daily recommended value is 4700mg
												- 12 bananas worth - of potassium, and I’m willing to bet that you’re not getting enough of it on a consistent basis.
											</p>
											<p>
												Read more about why potassium is so important here: <a target="_blank" href="potassium.pdf">-- Link to paper</a>
											</p>

										</header>
									</article>

									<article class="item" id="superpixels">
										<header>
											<h2 class="major"><strong>Superpixels!</strong></h2>
											<p>
												For my Parallel and Distributed Systems class, my partners and I chose to parallelize a superpixel segmentation algorithm called Simple Linear Iterative Clustering, or SLIC.
												We compared the runtime and boundary recall of our parallel implementation to the sequential implementation and found some interesting results!
												<br  />Below is an example of an image with superpixels boundaries superimposed onto it (shown in yellow)
											</p>
											<img src="images/mountain.png" class="image"/>

											<p>
												Abstract
											</p>

											<p>
												Superpixelation involves grouping pixels in a way that captures some of the perceptual and intuitive meaning of an image. Superpixels are a useful tool for many computer vision problems including image segmentation and object recognition because superpixelation can be used as a preprocessing step that both reduces dimensionality and identifies more meaningful features. A good superpixel algorithm efficiently produces superpixels that respect object boundaries, are of approximately equal size, and are compact -- this means that superpixel edges fall along the edges of objects in the image, there is a roughly constant number of pixels per superpixel, and that each superpixel is relatively round. We implement a parallelized version of the simple linear iterative clustering (SLIC) algorithm for superpixelation with the goal of improving time efficiency and possibly scaling to larger image sizes. SLIC uses a $k$-means clustering approach which iteratively updates the assignment of pixels to superpixels based on the distance between the pixel and the superpixel centers. It is a good candidate algorithm for GPU parallelization because it has subparts that can computed independently by pixel or by superpixel. Although our results show that our parallelized implementation is 4-5 times slower than the sequential SLIC, we achieve nearly the same accuracy using metrics calculated using UC Berkeley's Segmentation Benchmarks - especially as the number of superpixels increase.
											</p>

											<a target="_blank" href="cs87-project-report.pdf">-- Link to paper --</a>

										</header>
									</article>

									<article class="item" id="paces">
										<header>
											<h2 class="major"><strong>Paces Cafe</strong></h2>
											<p>
												Paces is a student-run cafe that is open from Sunday-Wednesday nights on Swarthmore College's campus. As a freshman, I joined the cafe as a prep chef. I was in charge of making guacamole and salsa
												for the week as well as prepping vegatables and special dishes for the week. I was promoted to Kitchen Director at the end of freshman year and proceeded to revamp the menu
												to provide healthier and tastier options, while also canning the dishes that had one-dimensional ingredients. I worked closely with the dining staff to conduct inventory and sales analysis
												to further increase our profit margins and reduce waste. In the first 4 months of joining the team of directors, revenue has increased 400% and we have reached our nightly capacity of the cafe.
												Swarthmore College is currently looking to rennovate a space to accommodate our sudden growth. I also interviewed, hired, and trained a team of 40 students and work closely with the staff and facilitate nightly operations
												so that we can all have a good time as both students and employees. Below is a menu that we began the second semester with.
											</p>
											<img src="images/paces_menu.jpg" class="image fit"/>

										</header>
									</article>


								</div>
							</div>
							<div class="row">
								<div class="6u 12u$(mobile)">
									<article class="item" id="reikiOM">
										<header>
											<h2 class="major">Reiki OM</h2>
											<p>
												Produced by Soundings of the Planet in 2011. I was the featured artist playing the GuZheng. <br />
												COVR Visionary Award Double Winner - Best Innerspace, Meditation, Healing Music and Music of the Year!
											</p>
											<p>
												I'm verified on Spotify! Find my profile on the left side bar and experience the benefits of Earth Resonance Frequency (ERF)! ERF helps entrain brainwaves to Alpha state.
											</p>
											<br />

											<iframe id='spotify' src="https://open.spotify.com/embed?uri=spotify:track:0N5TmseieQKlk1ydbfjjZg&view=coverart"
											width=80% height=80% frameborder="0" allowtransparency="true"></iframe>
										</header>
									</article>

									<article class="item" id="photography">
										<a target="_blank" href="http://vsco.co/hanksterhan/" class="image fit"><img src="images/tina_big_sur.jpg" alt="" /></a>
										<header>
											<h2 class="major">Traveling and Photography</h2>
											<p>
												I love to travel! Some of my most memorable trips have been to Banff, Canada; Dubai, UAE; Harare, Zimbabwe; KunMing, China; and Helsinki, Finland.
											</p>
											<p>
												I'm also getting into photography - check out my <a href="http://vsco.co/hanksterhan/">VSCO</a> to get a glimpse at what I've been up to!
											</p>
											<a target="_blank" href='http://vsco.co/hanksterhan/'><strong> -- Link to VSCO -- </strong></a>
										</header>
									</article>
								</div>

								<div class="6u 12u$(mobile)">
									<article class="item" id="latenite">
										<img src="images/sushi portrait.jpg" alt="" class="image fit"/>
										<header>
											<h2 class="major">Late Nite Swarthmore</h2>
											<p>
												Within 2 months of starting my freshmen year of college at Swarthmore College, I started a food delivery service
												that tackled the shortage of late night grub options on campus. Check out the menu <a target="_blank" href="https://orderfromlatenite.github.io">here</a>
											</p>
											<p>
												Scouted.io included me in their List of Top 5 Scouted Student Entrepreneurs:
												<a target="_blank" href="http://blog.scouted.io/2017/06/20/top-5-scouted-student-entrepreneurs/"> -- Scouted.io Blog --</a>
											</p>
											<p>
												Swarthmore College interviewed me for the article <a target="_blank" href="http://bulletin.swarthmore.edu/summer-2017-issue-iv-volume-cxiv/fish-tales#Han">"24 Ways to Look at a Fish"</a>
											</p>
										</header>
									</article>
								</div>
							</div>
							<div class="row">
								<div class="12u$ 12u$(mobile)">
									<article class="item" id="djai">
										<header>
											<h2 class="major">DJai</h2>
											<p>
												Using Spotify, DJai generates playlists based on user inputs like desired energy level and tempo.
												The web app automatically syncs the beats of consecutive songs and crossfades them as if a real DJ mixed the tracks!
												Generated playlists can also be exported to Spotify to be played in the future.

												<br /><br />
												Coming soon!<br />
												<a target="_blank" href="https://github.com/hanksterhan/DJai"> -- Link to Github --</a>
											</p>
										</header>
									</article>
								</div>
							</div>
						</div>
					</section>

				<!-- About Me -->
					<section id="about" class="three">
						<div class="container">

							<header>
								<h2>About Me</h2>
							</header>

							<img src="images/about_me.jpg" alt="" class="image featured"/>

							<p>
								I am a computer science and math double major at Swarthmore College graduating in the Spring of 2020. <br /> I am also passionate in the topics of psychology,
								neuroscience, and nutrition. I like to stay fit through basketball, tennis, hiking, and bodybuilding. I play many instruments, but mainly the piano and GuZheng.
								My favorite pieces include Grades etudes de Paganini by Franz Liszt, all three of Rachmaninioff's Piano Concertos, and Chopin Scherzo No.3 in C Sharp Minor, Op.39.
							</p>

							<p>
								On a journey to quench my thirst for knowledge
							</p>
						</div>
					</section>
			</div>

		<!-- Footer -->
			<!-- <div id="footer">

			</div> -->

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollzer.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
